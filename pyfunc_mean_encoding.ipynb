{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Encoding for Categorical Features\n",
    "\n",
    "Based on evaluating two potential approaches for implementing mean encoding functionality in our preprocessing pipeline, the preferred approach is creating a separate `MeanEncoder` class rather than integrating it directly into the existing `PreProcessor` class. This decision aligns with the Single Responsibility Principle and mirrors our current architecture, where numeric and categorical transformations are handled as distinct operations. A separate `MeanEncoder` class will not only be easier to test, maintain, and extend, but will also provide the flexibility to implement advanced features such as cross-validation folds and smoothing parameters. While this approach requires managing an additional class and its interactions, the benefits of improved modularity, reusability, and cleaner code organization outweigh these minor drawbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer for data preprocessing.\n",
    "    \n",
    "    - Scales numeric features\n",
    "    - Encodes categorical features\n",
    "    - Handles missing values via imputation\n",
    "    - Compatible with scikit-learn pipeline\n",
    "    \n",
    "    Attributes:\n",
    "        num_impute_strategy (str): Numeric imputation strategy\n",
    "        cat_impute_strategy (str): Categorical imputation strategy\n",
    "        num_transformer (Pipeline): Numeric preprocessing pipeline\n",
    "        cat_transformer (Pipeline): Categorical preprocessing pipeline\n",
    "        transformed_cat_cols (List[str]): One-hot encoded column names\n",
    "        num_features (List[str]): Numeric feature names\n",
    "        cat_features (List[str]): Categorical feature names\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_impute_strategy='median', \n",
    "                 cat_impute_strategy='most_frequent'):\n",
    "        \"\"\"\n",
    "        Initialize the transformer.\n",
    "        \n",
    "        - Sets up numeric data transformer\n",
    "        - Sets up categorical data transformer\n",
    "        - Configures imputation strategies\n",
    "        \n",
    "        Parameters:\n",
    "            num_impute_strategy (str): Strategy for numeric missing values\n",
    "            cat_impute_strategy (str): Strategy for categorical missing values\n",
    "        \"\"\"\n",
    "        self.num_impute_strategy = num_impute_strategy\n",
    "        self.cat_impute_strategy = cat_impute_strategy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit transformer on input data.\n",
    "        \n",
    "        - Identifies feature types\n",
    "        - Configures feature scaling\n",
    "        - Sets up encoding\n",
    "        - Fits imputation strategies\n",
    "        \n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input features\n",
    "            y (pd.Series, optional): Target variable, not used\n",
    "        \n",
    "        Returns:\n",
    "            CustomTransformer: Fitted transformer\n",
    "        \"\"\"\n",
    "        self.num_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "        self.cat_features = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "        if self.num_features:\n",
    "            self.num_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=self.num_impute_strategy)),\n",
    "                ('scaler', StandardScaler())\n",
    "            ])\n",
    "            self.num_transformer.fit(X[self.num_features])\n",
    "        \n",
    "        if self.cat_features:\n",
    "            self.cat_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=self.cat_impute_strategy)),\n",
    "                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ])\n",
    "            self.cat_transformer.fit(X[self.cat_features])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def get_transformed_cat_cols(self):\n",
    "        \"\"\"\n",
    "        Get transformed categorical column names.\n",
    "        \n",
    "        - Creates names after one-hot encoding\n",
    "        - Combines category with encoded values\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: One-hot encoded column names\n",
    "        \"\"\"\n",
    "        cat_cols = []\n",
    "        cats = self.cat_features\n",
    "        cat_values = self.cat_transformer['encoder'].categories_\n",
    "        for cat, values in zip(cats, cat_values):\n",
    "            cat_cols += [f'{cat}_{value}' for value in values]\n",
    "        \n",
    "        return cat_cols\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform input data.\n",
    "        \n",
    "        - Applies fitted scaling\n",
    "        - Applies fitted encoding\n",
    "        - Handles numeric and categorical features\n",
    "        \n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input features\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Transformed data\n",
    "        \"\"\"\n",
    "        X_transformed = pd.DataFrame()\n",
    "\n",
    "        if self.num_features:\n",
    "            transformed_num_data = self.num_transformer.transform(X[self.num_features])\n",
    "            X_transformed[self.num_features] = transformed_num_data\n",
    "        \n",
    "        if self.cat_features:\n",
    "            transformed_cat_data = self.cat_transformer.transform(X[self.cat_features]).toarray()\n",
    "            self.transformed_cat_cols = self.get_transformed_cat_cols()\n",
    "            transformed_cat_df = pd.DataFrame(transformed_cat_data, columns=self.transformed_cat_cols)\n",
    "            X_transformed = pd.concat([X_transformed, transformed_cat_df], axis=1)\n",
    "        \n",
    "        X_transformed.index = X.index\n",
    "\n",
    "        return X_transformed\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit and transform input data.\n",
    "        \n",
    "        - Fits transformer to data\n",
    "        - Applies transformation\n",
    "        - Combines both operations\n",
    "        \n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input features\n",
    "            y (pd.Series, optional): Target variable, not used\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Transformed data\n",
    "        \"\"\"\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
