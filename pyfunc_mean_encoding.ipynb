{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Encoding for Categorical Features\n",
    "\n",
    "Based on evaluating two potential approaches for implementing mean encoding functionality in our preprocessing pipeline, the preferred approach is creating a separate `MeanEncoder` class rather than integrating it directly into the existing `PreProcessor` class. This decision aligns with the Single Responsibility Principle and mirrors our current architecture, where numeric and categorical transformations are handled as distinct operations. A separate `MeanEncoder` class will not only be easier to test, maintain, and extend, but will also provide the flexibility to implement advanced features such as cross-validation folds and smoothing parameters. While this approach requires managing an additional class and its interactions, the benefits of improved modularity, reusability, and cleaner code organization outweigh these minor drawbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanEncoder Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Scratch or Existing Package\n",
    "\n",
    "**Using Existing Package**\n",
    "Packages like `category_encoders` can be used in MeanEncoder. The pros and cons of this approach:\n",
    "* Pros:\n",
    "    * Proven, tested code\n",
    "    * Immediate access to multiple encoding strategies\n",
    "    * Community support and bug fixes\n",
    "    * Time-saving for basic functionality\n",
    "* Cons:\n",
    "    * Less control over implementation details\n",
    "    * May include unnecessary dependencies\n",
    "    * Harder to customize or extend in specific ways\n",
    "    * May not perfectly match our specific needs\n",
    "\n",
    "**Building from Scratch** \n",
    "* Pros:\n",
    "    * Complete control over implementation\n",
    "    * Can perfectly match our specific requirements\n",
    "    * Better understanding of the codebase\n",
    "    * Easier to extend with custom functionality\n",
    "    * No external dependencies\n",
    "* Cons:\n",
    "    * More time to implement\n",
    "    * Need to write own tests\n",
    "    * Need to handle edge cases ourselves\n",
    "    * Risk of introducing bugs\n",
    "\n",
    "**Recommendations**: Given that we want to build sophisticated, extendable functionality, building from scratch is recommended because:\n",
    "* We'll need fine-grained control over CV and smoothing implementations\n",
    "* We might want to add custom features specific to our use case\n",
    "* The core mean encoding logic is relatively straightforward\n",
    "* We can start simple and gradually add complexity\n",
    "\n",
    "Moreover, we could still use category_encoders as a reference for best practices and edge case handling. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeanEncoder Version 1\n",
    "\n",
    "Let's start simple: This version only gets the category mean as the encoded values. As suggested at the top, TargetEncoder from `category_encoders` is leveraged for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Basic mean encoder for categorical features.\n",
    "    Maps each category to the mean of target values for that category.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.encodings = {}\n",
    "        self.global_means = {}\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if y is None:\n",
    "            raise ValueError(\"Target variable y is required for mean encoding\")\n",
    "            \n",
    "        # Process each feature\n",
    "        for column in X.columns:\n",
    "            # Calculate global mean as fallback for unknown categories\n",
    "            self.global_means[column] = y.mean()\n",
    "            \n",
    "            # Calculate mean target value for each category\n",
    "            self.encodings[column] = y.groupby(X[column]).mean()\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_encoded = pd.DataFrame(index=X.index)\n",
    "        \n",
    "        for column in X.columns:\n",
    "            # Map categories to their mean target values\n",
    "            # Use global mean for unknown categories\n",
    "            X_encoded[column] = X[column].map(self.encodings[column]).fillna(self.global_means[column])\n",
    "            \n",
    "        return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual means per category_1:\n",
      "category_1\n",
      "A    0.757576\n",
      "B    0.638889\n",
      "C    0.193548\n",
      "dtype: float64\n",
      "\n",
      "First few rows comparison:\n",
      "\n",
      "Original data with our encoding:\n",
      "  category_1 category_2  category_1_our_encoded  category_2_our_encoded  \\\n",
      "0          C          Z                0.193548                0.500000   \n",
      "1          A          Z                0.757576                0.500000   \n",
      "2          C          Z                0.193548                0.500000   \n",
      "3          C          X                0.193548                0.575758   \n",
      "4          A          Z                0.757576                0.500000   \n",
      "\n",
      "   category_1_ce_encoded  category_2_ce_encoded  \n",
      "0               0.193554               0.500000  \n",
      "1               0.757575               0.500000  \n",
      "2               0.193554               0.500000  \n",
      "3               0.193554               0.575757  \n",
      "4               0.757575               0.500000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Create demo dataset for testing\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'category_1': np.random.choice(['A', 'B', 'C'], size=100),\n",
    "    'category_2': np.random.choice(['X', 'Y', 'Z'], size=100),\n",
    "})\n",
    "target = pd.Series([\n",
    "    np.random.binomial(1, 0.8) if cat == 'A' else\n",
    "    np.random.binomial(1, 0.5) if cat == 'B' else\n",
    "    np.random.binomial(1, 0.2)\n",
    "    for cat in data['category_1']\n",
    "])\n",
    "\n",
    "# Test our implementation\n",
    "our_encoder = MeanEncoder()\n",
    "our_encoded = our_encoder.fit_transform(data, target)\n",
    "\n",
    "# Test category_encoders implementation\n",
    "ce_encoder = TargetEncoder(smoothing=1.0)\n",
    "ce_encoded = ce_encoder.fit_transform(data, target)\n",
    "\n",
    "# Show actual means for reference\n",
    "print(\"Actual means per category_1:\")\n",
    "print(target.groupby(data['category_1']).mean())\n",
    "\n",
    "# Comparison\n",
    "print(\"\\nFirst few rows comparison:\")\n",
    "print(\"\\nOriginal data with our encoding:\")\n",
    "comparison = pd.concat([\n",
    "    data.head(),\n",
    "    our_encoded.head().add_suffix('_our_encoded'),\n",
    "    ce_encoded.head().add_suffix('_ce_encoded')\n",
    "], axis=1)\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporating into PreProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer for data preprocessing.\n",
    "    \n",
    "    - Scales numeric features\n",
    "    - Encodes categorical features\n",
    "    - Handles missing values via imputation\n",
    "    - Compatible with scikit-learn pipeline\n",
    "    \n",
    "    Attributes:\n",
    "        num_impute_strategy (str): Numeric imputation strategy\n",
    "        cat_impute_strategy (str): Categorical imputation strategy\n",
    "        num_transformer (Pipeline): Numeric preprocessing pipeline\n",
    "        cat_transformer (Pipeline): Categorical preprocessing pipeline\n",
    "        transformed_cat_cols (List[str]): One-hot encoded column names\n",
    "        num_features (List[str]): Numeric feature names\n",
    "        cat_features (List[str]): Categorical feature names\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_impute_strategy='median', \n",
    "                 cat_impute_strategy='most_frequent'):\n",
    "        \"\"\"\n",
    "        Initialize the transformer.\n",
    "        \n",
    "        - Sets up numeric data transformer\n",
    "        - Sets up categorical data transformer\n",
    "        - Configures imputation strategies\n",
    "        \n",
    "        Parameters:\n",
    "            num_impute_strategy (str): Strategy for numeric missing values\n",
    "            cat_impute_strategy (str): Strategy for categorical missing values\n",
    "            mean_encode_cols (List[str]): Columns to apply mean encoding\n",
    "        \"\"\"\n",
    "        self.num_impute_strategy = num_impute_strategy\n",
    "        self.cat_impute_strategy = cat_impute_strategy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit transformer on input data.\n",
    "        \n",
    "        - Identifies feature types\n",
    "        - Configures feature scaling\n",
    "        - Sets up encoding\n",
    "        - Fits imputation strategies\n",
    "        \n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input features\n",
    "            y (pd.Series, optional): Target variable, not used\n",
    "        \n",
    "        Returns:\n",
    "            CustomTransformer: Fitted transformer\n",
    "        \"\"\"\n",
    "        self.num_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "        self.cat_features = [col for col in X.select_dtypes(exclude=np.number).columns if col not in (self.mean_encode_cols or [])]\n",
    "\n",
    "        # Handle mean encoding features\n",
    "        if self.mean_encode_cols:\n",
    "            self.mean_encoder = MeanEncoder()\n",
    "            mean_encode_features = [f for f in self.mean_encode_cols if f in X.columns]\n",
    "            if mean_encode_features:\n",
    "                self.mean_encoder.fit(X[mean_encode_features], y)\n",
    "\n",
    "        if self.num_features:\n",
    "            self.num_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=self.num_impute_strategy)),\n",
    "                ('scaler', StandardScaler())\n",
    "            ])\n",
    "            self.num_transformer.fit(X[self.num_features])\n",
    "        \n",
    "        if self.cat_features:\n",
    "            self.cat_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=self.cat_impute_strategy)),\n",
    "                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ])\n",
    "            self.cat_transformer.fit(X[self.cat_features])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def get_transformed_cat_cols(self):\n",
    "        \"\"\"\n",
    "        Get transformed categorical column names.\n",
    "        \n",
    "        - Creates names after one-hot encoding\n",
    "        - Combines category with encoded values\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: One-hot encoded column names\n",
    "        \"\"\"\n",
    "        cat_cols = []\n",
    "        cats = self.cat_features\n",
    "        cat_values = self.cat_transformer['encoder'].categories_\n",
    "        for cat, values in zip(cats, cat_values):\n",
    "            cat_cols += [f'{cat}_{value}' for value in values]\n",
    "        \n",
    "        return cat_cols\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform input data.\n",
    "        \n",
    "        - Applies fitted scaling\n",
    "        - Applies fitted encoding\n",
    "        - Handles numeric and categorical features\n",
    "        \n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input features\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Transformed data\n",
    "        \"\"\"\n",
    "        X_transformed = pd.DataFrame()\n",
    "\n",
    "        if self.mean_encode_cols and hasattr(self, 'mean_encoder'):\n",
    "            mean_encoded_features = self.mean_encoder.transform(X[self.mean_encode_cols])\n",
    "            X_transformed = pd.concat([X_transformed, mean_encoded_features], axis=1)\n",
    "\n",
    "        if self.num_features:\n",
    "            transformed_num_data = self.num_transformer.transform(X[self.num_features])\n",
    "            X_transformed[self.num_features] = transformed_num_data\n",
    "        \n",
    "        if self.cat_features:\n",
    "            transformed_cat_data = self.cat_transformer.transform(X[self.cat_features]).toarray()\n",
    "            self.transformed_cat_cols = self.get_transformed_cat_cols()\n",
    "            transformed_cat_df = pd.DataFrame(transformed_cat_data, columns=self.transformed_cat_cols)\n",
    "            X_transformed = pd.concat([X_transformed, transformed_cat_df], axis=1)\n",
    "        \n",
    "        X_transformed.index = X.index\n",
    "\n",
    "        return X_transformed\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit and transform input data.\n",
    "        \n",
    "        - Fits transformer to data\n",
    "        - Applies transformation\n",
    "        - Combines both operations\n",
    "        \n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input features\n",
    "            y (pd.Series, optional): Target variable, not used\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Transformed data\n",
    "        \"\"\"\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
