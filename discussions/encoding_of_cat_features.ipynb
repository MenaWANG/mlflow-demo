{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding of Categorical Features with Many Values\n",
    "\n",
    "Categorical features are a common occurrence in many datasets. However, they can pose a challenge when it comes to modeling, especially when there are many unique values. This notebook explores different techniques for encoding categorical features with many values, including frequency-based encoding, target-based encoding, clustering similar categories, and hash encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4000 entries, 4227 to 860\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   category            4000 non-null   object \n",
      " 1   numeric_feature     4000 non-null   float64\n",
      " 2   category_grouped    4000 non-null   object \n",
      " 3   category_encoded    4000 non-null   float64\n",
      " 4   category_clustered  4000 non-null   object \n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 187.5+ KB\n",
      "Frequency-Based Encoding:\n",
      "      category category_grouped\n",
      "4227   cat_76            Other\n",
      "4676   cat_43            Other\n",
      "800    cat_27            Other\n",
      "3671   cat_51           cat_51\n",
      "4193   cat_47           cat_47\n",
      "\n",
      "Target-Based Encoding:\n",
      "      category  category_encoded\n",
      "4227   cat_76          0.512932\n",
      "4676   cat_43          0.502257\n",
      "800    cat_27          0.418742\n",
      "3671   cat_51          0.426910\n",
      "4193   cat_47          0.535024\n",
      "\n",
      "Clustering Similar Categories:\n",
      "      category category_clustered\n",
      "4227   cat_76                 76\n",
      "4676   cat_43                 43\n",
      "800    cat_27                 27\n",
      "3671   cat_51                 51\n",
      "4193   cat_47                 47\n",
      "\n",
      "Hash Encoding:\n",
      "      category  hash_0  hash_1  hash_2  hash_3  hash_4  hash_5  hash_6  hash_7  \\\n",
      "4227   cat_76     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "4676   cat_43     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "800    cat_27     0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
      "3671   cat_51    -1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4193   cat_47     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "      hash_8  hash_9  \n",
      "4227     NaN     NaN  \n",
      "4676     NaN     NaN  \n",
      "800      0.0     0.0  \n",
      "3671     0.0     0.0  \n",
      "4193     NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "# Create synthetic dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "categories = [f'cat_{i}' for i in range(1, 101)]  # 100 unique categories\n",
    "data = {\n",
    "    'category': np.random.choice(categories, n_samples),\n",
    "    'numeric_feature': np.random.randn(n_samples),\n",
    "    'target': np.random.randint(0, 2, n_samples)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Frequency-Based Encoding\n",
    "threshold = 0.01  # 1% frequency\n",
    "value_counts = X_train['category'].value_counts(normalize=True)\n",
    "top_categories = value_counts[value_counts > threshold].index\n",
    "X_train['category_grouped'] = X_train['category'].apply(lambda x: x if x in top_categories else 'Other')\n",
    "X_test['category_grouped'] = X_test['category'].apply(lambda x: x if x in top_categories else 'Other')\n",
    "\n",
    "# 2. Target-Based Encoding (Mean-Encoding)\n",
    "encoder = TargetEncoder()\n",
    "encoder.fit(X_train['category'], y_train)\n",
    "X_train['category_encoded'] = encoder.transform(X_train['category']).values\n",
    "X_test['category_encoded'] = encoder.transform(X_test['category']).values\n",
    "\n",
    "# 3. Clustering Similar Categories \n",
    "# For demonstration, let's assume categories with similar suffixes are similar\n",
    "X_train['category_clustered'] = X_train['category'].apply(lambda x: x.split('_')[1])\n",
    "X_test['category_clustered'] = X_test['category'].apply(lambda x: x.split('_')[1])\n",
    "\n",
    "\n",
    "# 4. Hash Encoding\n",
    "hasher = FeatureHasher(n_features=10, input_type='string')\n",
    "hashed_features_train = hasher.transform(X_train['category'].apply(lambda x: [x]))\n",
    "hashed_features_test = hasher.transform(X_test['category'].apply(lambda x: [x]))\n",
    "hashed_df_train = pd.DataFrame(hashed_features_train.toarray(), columns=[f'hash_{i}' for i in range(10)])\n",
    "hashed_df_test = pd.DataFrame(hashed_features_test.toarray(), columns=[f'hash_{i}' for i in range(10)])\n",
    "\n",
    "# Add hashed features to original data\n",
    "X_train = pd.concat([X_train, hashed_df_train], axis=1)\n",
    "X_test = pd.concat([X_test, hashed_df_test], axis=1)\n",
    "\n",
    "\n",
    "# Display the transformed datasets\n",
    "print(\"Frequency-Based Encoding:\\n\", X_train[['category', 'category_grouped']].head())\n",
    "print(\"\\nTarget-Based Encoding:\\n\", X_train[['category', 'category_encoded']].head())\n",
    "print(\"\\nClustering Similar Categories:\\n\", X_train[['category', 'category_clustered']].head())\n",
    "print(\"\\nHash Encoding:\\n\", X_train[['category'] + [f'hash_{i}' for i in range(10)]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collisions in Hash-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 100 categories mapped to 10 features, there will very likely be collisions. \n",
    "- Each category needs a unique representation\n",
    "- With 10 features, each having 3 possible values (-1, 0, 1)\n",
    "- Maximum unique combinations = 3^10 ≈ 59,049\n",
    "- But most combinations will be sparse (mostly zeros)\n",
    "- Actual unique patterns much fewer than 59,049\n",
    "- If the sparse vectors were well-distributed and the hashing mechanism perfectly balanced, the collisions might not always happen—but this scenario is extremely unlikely.\n",
    "\n",
    "Let's demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 100\n",
      "Number of unique hash patterns: 20\n",
      "\n",
      "Example of collisions:\n",
      "\n",
      "Categories sharing pattern [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]:\n",
      "['cat_0' 'cat_1' 'cat_54' 'cat_84']\n",
      "\n",
      "Categories sharing pattern [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]:\n",
      "['cat_0' 'cat_1' 'cat_54' 'cat_84']\n",
      "\n",
      "Categories sharing pattern [ 0.  0.  0. -1.  0.  0.  0.  0.  0.  0.]:\n",
      "['cat_2' 'cat_3' 'cat_66' 'cat_95']\n",
      "\n",
      "Categories sharing pattern [ 0.  0.  0. -1.  0.  0.  0.  0.  0.  0.]:\n",
      "['cat_2' 'cat_3' 'cat_66' 'cat_95']\n",
      "\n",
      "Categories sharing pattern [ 0.  0.  0.  0.  0.  0.  0. -1.  0.  0.]:\n",
      "['cat_4' 'cat_8' 'cat_19' 'cat_32' 'cat_41' 'cat_57' 'cat_71' 'cat_78']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "# Create dataset with 100 categories\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'category': [f'cat_{i}' for i in range(100)]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Hash to 10 features\n",
    "hasher = FeatureHasher(n_features=10, input_type='string')\n",
    "hashed_features = hasher.transform(df['category'].apply(lambda x: [x]))\n",
    "hashed_df = pd.DataFrame(\n",
    "    hashed_features.toarray(), \n",
    "    columns=[f'hash_{i}' for i in range(10)]\n",
    ")\n",
    "\n",
    "# Check for unique representations\n",
    "unique_patterns = hashed_df.drop_duplicates()\n",
    "print(f\"Number of categories: {len(df)}\")\n",
    "print(f\"Number of unique hash patterns: {len(unique_patterns)}\")\n",
    "\n",
    "# Show some examples of collisions\n",
    "print(\"\\nExample of collisions:\")\n",
    "for pattern in hashed_df.values[:5]:\n",
    "    matching_cats = df[hashed_df.apply(lambda x: all(x == pattern), axis=1)]['category']\n",
    "    if len(matching_cats) > 1:\n",
    "        print(f\"\\nCategories sharing pattern {pattern}:\")\n",
    "        print(matching_cats.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target encoding and data leakage\n",
    "\n",
    "Target encoding can lead to data leakage because it uses target information to encode categories. \n",
    "\n",
    "Solutions:\n",
    "- Split data before encoding\n",
    "- Use cross-validation for encoding for more robust estimates\n",
    "- Consider smoothing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original vs CV-encoded values:\n",
      "  category  target  encoded_cv\n",
      "0        D       1    0.466667\n",
      "1        E       1    0.503226\n",
      "2        C       1    0.532895\n",
      "3        E       1    0.503226\n",
      "4        E       1    0.503226\n",
      "5        B       0    0.428572\n",
      "6        C       1    0.532895\n",
      "7        C       0    0.532895\n",
      "8        C       1    0.532895\n",
      "9        E       0    0.503226\n",
      "\n",
      "Average encoding per category:\n",
      "category\n",
      "A    0.454023\n",
      "B    0.428572\n",
      "C    0.532895\n",
      "D    0.466667\n",
      "E    0.503226\n",
      "Name: encoded_cv, dtype: float64\n",
      "Bad Practice (with leakage):\n",
      "   category  target  encoded_bad\n",
      "0        D       1     0.475728\n",
      "1        E       1     0.504902\n",
      "2        C       1     0.536842\n",
      "3        E       1     0.504902\n",
      "4        E       1     0.504902\n",
      "\n",
      "Good Practice (train set):\n",
      "     category   encoded\n",
      "29         D  0.461538\n",
      "535        E  0.552941\n",
      "695        B  0.468532\n",
      "557        E  0.552941\n",
      "836        B  0.468532\n",
      "\n",
      "Good Practice (CV):\n",
      "   category  target  encoded_cv\n",
      "0        D       1    0.466667\n",
      "1        E       1    0.503226\n",
      "2        C       1    0.532895\n",
      "3        E       1    0.503226\n",
      "4        E       1    0.503226\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create sample data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "data = {\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D', 'E'], n_samples),\n",
    "    'target': np.random.randint(0, 2, n_samples)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Bad Practice (Data Leakage)\n",
    "encoder_bad = TargetEncoder()\n",
    "df['encoded_bad'] = encoder_bad.fit_transform(df['category'], df['target'])\n",
    "\n",
    "# Good Practice 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['category']], df['target'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "encoder_good = TargetEncoder()\n",
    "encoder_good.fit(X_train['category'], y_train)\n",
    "X_train['encoded'] = encoder_good.transform(X_train['category']).values\n",
    "X_test['encoded'] = encoder_good.transform(X_test['category']).values\n",
    "\n",
    "# Good Practice 2: K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "df['encoded_cv'] = np.nan\n",
    "\n",
    "for train_idx, val_idx in kf.split(df):\n",
    "    # Get train and validation sets\n",
    "    encoder = TargetEncoder()\n",
    "    \n",
    "    # Fit the encoder using training fold\n",
    "    encoder.fit(\n",
    "        df.iloc[train_idx]['category'], \n",
    "        df.iloc[train_idx]['target']\n",
    "    )\n",
    "    \n",
    "    # Transform the training and validation fold\n",
    "    df.loc[train_idx, 'encoded_cv'] = encoder.transform(df.iloc[train_idx]['category']).values\n",
    "    df.loc[val_idx, 'encoded_cv'] = encoder.transform(df.iloc[val_idx]['category']).values\n",
    "\n",
    "print(\"\\nOriginal vs CV-encoded values:\")\n",
    "print(df[['category', 'target', 'encoded_cv']].head(10))\n",
    "\n",
    "# Show average encoding per category\n",
    "print(\"\\nAverage encoding per category:\")\n",
    "print(df.groupby('category')['encoded_cv'].mean())\n",
    "\n",
    "print(\"Bad Practice (with leakage):\\n\", df[['category', 'target', 'encoded_bad']].head())\n",
    "print(\"\\nGood Practice (train set):\\n\", X_train[['category', 'encoded']].head())\n",
    "print(\"\\nGood Practice (CV):\\n\", df[['category', 'target', 'encoded_cv']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  CV vs simple mean of means\n",
    "\n",
    "1. Independence:  \n",
    "* CV encoding: Each sample's encoding is independent of its own target value   \n",
    "* Mean of means: Every sample influences all encodings     \n",
    "\n",
    "2. Leakage:\n",
    "* CV encoding: No leakage because samples are encoded with means calculated without them\n",
    "* Mean of means: Contains information from all samples\n",
    "\n",
    "3. Robustness:\n",
    "* CV encoding: More robust because each sample gets an \"unbiased\" encoding\n",
    "* Mean of means: More prone to overfitting\n",
    "\n",
    "In summary, the CV approach gives us a more realistic estimate of how the encoding will perform on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original target means per category:\n",
      "cat1\n",
      "A    0.666667\n",
      "B    0.333333\n",
      "Name: target, dtype: float64\n",
      "\n",
      "CV encoding means per category:\n",
      "cat1\n",
      "A    0.666784\n",
      "B    0.333242\n",
      "Name: encoded_cv, dtype: float64\n",
      "\n",
      "Simple mean of train_means:\n",
      "cat1\n",
      "A    0.666690\n",
      "B    0.333315\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create sample data with clear patterns\n",
    "data = {\n",
    "    'cat1': ['A', 'A', 'A', 'B', 'B', 'B'] * 200,  # 1000 samples\n",
    "    'target': [1, 1, 0, 0, 0, 1] * 200  # A has 67% 1s, B has 33% 1s\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['encoded_cv'] = np.nan  # CV encoding\n",
    "df['encoded_mean'] = np.nan  # Simple mean of train means\n",
    "\n",
    "# Store train means from each fold\n",
    "all_train_means = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Method 1: CV encoding\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df, df['target'])):\n",
    "    # Calculate means from training fold\n",
    "    train_means = df.iloc[train_idx].groupby('cat1')['target'].mean()\n",
    "    all_train_means.append(train_means)    \n",
    "    df.loc[val_idx, 'encoded_cv'] = df.loc[val_idx, 'cat1'].map(train_means)\n",
    "    # alternatively, below gives the same result\n",
    "    # encoder = TargetEncoder()\n",
    "    # encoder.fit(df.iloc[train_idx]['cat1'], df.iloc[train_idx]['target'])\n",
    "    # df.loc[val_idx, 'encoded_cv'] = encoder.transform(df.iloc[val_idx]['cat1']).values\n",
    "\n",
    "# Method 2: Average of all train means\n",
    "mean_of_means = pd.concat(all_train_means, axis=1).mean(axis=1)\n",
    "df['encoded_mean'] = df['cat1'].map(mean_of_means)\n",
    "\n",
    "print(\"Original target means per category:\")\n",
    "print(df.groupby('cat1')['target'].mean())\n",
    "\n",
    "print(\"\\nCV encoding means per category:\")\n",
    "print(df.groupby('cat1')['encoded_cv'].mean())\n",
    "\n",
    "print(\"\\nSimple mean of train_means:\")\n",
    "print(mean_of_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original target means per category:\n",
      "cat1\n",
      "A    0.666667\n",
      "B    0.333333\n",
      "Name: target, dtype: float64\n",
      "\n",
      "CV encoding means per category:\n",
      "cat1\n",
      "A    0.666784\n",
      "B    0.333242\n",
      "Name: encoded_cv, dtype: float64\n",
      "\n",
      "Simple mean of train_means:\n",
      "cat1\n",
      "A    0.666690\n",
      "B    0.333315\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create sample data with clear patterns\n",
    "data = {\n",
    "    'cat1': ['A', 'A', 'A', 'B', 'B', 'B'] * 200,  # 1000 samples\n",
    "    'target': [1, 1, 0, 0, 0, 1] * 200  # A has 67% 1s, B has 33% 1s\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['encoded_cv'] = np.nan  # CV encoding\n",
    "df['encoded_mean'] = np.nan  # Simple mean of train means\n",
    "\n",
    "# Store train means from each fold\n",
    "all_train_means = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Method 1: CV encoding\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df, df['target'])):\n",
    "    # Calculate means from training fold\n",
    "    train_means = df.iloc[train_idx].groupby('cat1')['target'].mean()\n",
    "    all_train_means.append(train_means)\n",
    "    encoder = TargetEncoder()\n",
    "    encoder.fit(df.iloc[train_idx]['cat1'], df.iloc[train_idx]['target'])\n",
    "    df.loc[val_idx, 'encoded_cv'] = encoder.transform(df.iloc[val_idx]['cat1']).values\n",
    "\n",
    "# Method 2: Average of all train means\n",
    "mean_of_means = pd.concat(all_train_means, axis=1).mean(axis=1)\n",
    "df['encoded_mean'] = df['cat1'].map(mean_of_means)\n",
    "\n",
    "print(\"Original target means per category:\")\n",
    "print(df.groupby('cat1')['target'].mean())\n",
    "\n",
    "print(\"\\nCV encoding means per category:\")\n",
    "print(df.groupby('cat1')['encoded_cv'].mean())\n",
    "\n",
    "print(\"\\nSimple mean of train_means:\")\n",
    "print(mean_of_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other considerations and discussions\n",
    "\n",
    "\n",
    "* Handle of tiny cateogires: Would it be a good idae to combine mean encoding and frequency encoding? \n",
    "* Should we have a separate encoder class or integrate it to PreProcessor?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
